# -*- coding: utf-8 -*-
"""HeartDiseasePredictor

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qAMVtVZ7_lkzVNn41_dxjj7Fce75eGgN
"""

import numpy as np
import pandas as pd
import warnings
warnings.filterwarnings('ignore')

heart_df = pd.read_csv("/content/heart.csv")
heart_df

heart_df.sample(5)

heart_df.info()

heart_df.describe()

heart_df.describe(include="all")

heart_df.isnull().sum()

heart_df.duplicated().sum()

heart_df.nunique()

cat_col=heart_df.select_dtypes(include='object').columns

heart_df['ChestPainType'].unique()

range(heart_df['ChestPainType'].nunique())

for col in cat_col:
    print(col)
    print((heart_df[col].unique()), list(range(heart_df[col].nunique())))
    heart_df[col].replace((heart_df[col].unique()), range(heart_df[col].nunique()), inplace=True)
    print('*'*90)
    print()

heart_df

heart_df['Cholesterol'].value_counts()

heart_df['Cholesterol'].replace(0,np.nan, inplace=True)

from sklearn.impute import KNNImputer
imputer= KNNImputer(n_neighbors=3)
after_impute=imputer.fit_transform(heart_df)
heart_df=pd.DataFrame(after_impute, columns=heart_df.columns)

heart_df['Cholesterol'].isna().sum()

count=0
for i in heart_df['Cholesterol']:
  if i==0:
    count+=1
print(count)

heart_df['RestingBP'][heart_df['RestingBP']==0]

from sklearn.impute import KNNImputer
heart_df['RestingBP'].replace(0, np.nan, inplace=True)
imputer = KNNImputer(n_neighbors=3)
after_impute = imputer.fit_transform(heart_df)
heart_df = pd.DataFrame(after_impute, columns=heart_df.columns)

heart_df['RestingBP'].unique()

heart_df['RestingBP'].isnull().sum()

withoutOldPeak=heart_df.columns
withoutOldPeak=withoutOldPeak.drop('Oldpeak')
heart_df[withoutOldPeak]=heart_df[withoutOldPeak].astype('int32')

heart_df.info()

pip install plotly

heart_df.sample()

heart_df.corr()['HeartDisease'][:-1].sort_values()

import plotly.express as px

px.line(heart_df.corr()['HeartDisease'][:-1].sort_values())

px.sunburst(heart_df, path=['HeartDisease','Age'])

px.histogram(heart_df,x='Age',color='HeartDisease')

px.pie(heart_df,names='HeartDisease',title='Percentage of HeartDisease classes distribution')

px.histogram(heart_df,x='Sex',color='HeartDisease')

px.histogram(heart_df, x='ChestPainType',color='HeartDisease')

heart_df['RestingBP'].unique()

px.sunburst(heart_df,path=['HeartDisease','RestingBP'])

px.histogram(heart_df,x='FastingBS',color='HeartDisease')

px.sunburst(heart_df,path=['HeartDisease','MaxHR'])

px.violin(heart_df, x='HeartDisease', y='MaxHR', color='HeartDisease')

px.violin(heart_df, x='HeartDisease', y='Oldpeak', color='HeartDisease')

px.histogram(heart_df, x='ST_Slope', color='HeartDisease')

px.histogram(heart_df, x='ExerciseAngina', color='HeartDisease')

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    heart_df.drop('HeartDisease', axis=1),
    heart_df['HeartDisease'],
    test_size=0.2,
    random_state=42,
    stratify=heart_df['HeartDisease']
)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import numpy as np

solver = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']
best_solver = ''
test_score = np.zeros(6)
for i, n in enumerate(solver):
    lr = LogisticRegression(solver=n).fit(X_train, y_train)
    test_score[i] = lr.score(X_test, y_test)
    if lr.score(X_test, y_test) == test_score.max():
        best_solver = n

print(best_solver)
lr = LogisticRegression(solver=best_solver)
lr.fit(X_train, y_train)
lr_pred = lr.predict(X_test)
print(f'LogisticRegression Score: {accuracy_score(y_test, lr_pred)}')

import pickle
file=open('LogisticR.pkl','wb')
pickle.dump(lr,file)

from sklearn.svm import SVC
from sklearn.metrics import f1_score

kernels = {'linear':0, 'poly':0, 'rbf':0, 'sigmoid':0}
best = ''
for i in kernels:
    svm = SVC(kernel=i)
    svm.fit(X_train, y_train)
    yhat = svm.predict(X_test)
    kernels[i] = f1_score(y_test, yhat, average="weighted")
    if kernels[i] == max(kernels.values()):
        best = i

print(best)
svm = SVC(kernel=best)
svm.fit(X_train, y_train)
svm_pred = svm.predict(X_test)
print(f'SVM f1_score kernel({best}): {f1_score(y_test, svm_pred, average="weighted")}')

import pickle
file = open('SVM_Model.pkl', 'wb')
pickle.dump(svm, file)

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

dtree = DecisionTreeClassifier(class_weight='balanced')
param_grid = {
    'max_depth': [3, 4, 5, 6, 7, 8],
    'min_samples_split': [2, 3, 4],
    'min_samples_leaf': [1, 2, 3, 4],
    'random_state': [0, 42]
}

grid_search = GridSearchCV(dtree, param_grid, cv=5)
grid_search.fit(X_train, y_train)

Ctree = DecisionTreeClassifier(**grid_search.best_params_, class_weight='balanced')
Ctree.fit(X_train, y_train)
dtc_pred = Ctree.predict(X_test)
print("DecisionTree's Accuracy: ", accuracy_score(y_test, dtc_pred))

import pickle
file = open('DecisionTree.pkl', 'wb')
pickle.dump(Ctree, file)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

rfc = RandomForestClassifier()
param_grid = {
    'n_estimators': [50, 100, 150, 500],
    'max_features': ['sqrt', 'log2', None],
    'max_depth': [3, 6, 9, 19],
    'max_leaf_nodes': [3, 6, 9]
}

grid_search = GridSearchCV(rfc, param_grid, cv=5)
grid_search.fit(X_train, y_train)

rfctree = RandomForestClassifier(**grid_search.best_params_)
rfctree.fit(X_train, y_train)
rfc_pred = rfctree.predict(X_test)
print("RandomForestClassifier's Accuracy: ", accuracy_score(y_test, rfc_pred))

import pickle
file = open('RandomForest.pkl', 'wb')
pickle.dump(rfctree, file)

from google.colab import files
files.download("RandomForest.pkl")
files.download("DecisionTree.pkl")
files.download("SVM_Model.pkl")
files.download("LogisticR.pkl")